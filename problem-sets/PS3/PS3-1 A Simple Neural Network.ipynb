{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## PS3-1 A Simple Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### (a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Recall the following equations:\n",
    "\n",
    "\\begin{align*}\n",
    "z^{[1]} & = W^{[1]} x + W_0^{[1]} \\\\\n",
    "h & = \\sigma (z^{[1]}) \\\\\n",
    "z^{[2]} & = W^{[2]} h + W_0^{[2]} \\\\\n",
    "o & = \\sigma (z^{[2]}) \\\\\n",
    "\\ell & = \\frac{1}{m} \\sum_{i = 1}^{m} (o^{(i)} - y^{(i)})^2 = \\frac{1}{m} \\sum_{i = 1}^{m} J^{(i)}\n",
    "\\end{align*}\n",
    "\n",
    "For a single training example,\n",
    "\n",
    "\\begin{align*}\n",
    "\\frac{\\partial J}{\\partial w_{1,2}^{[1]}} & = \\frac{\\partial J}{\\partial o} \\frac{\\partial o}{\\partial z^{[2]}} \\frac{\\partial z^{[2]}}{\\partial h_2} \\frac{\\partial h_2}{\\partial z_2^{[1]}} \\frac{\\partial z_2^{[1]}}{\\partial w_{1,2}^{[1]}} \\\\\n",
    "                                          & = 2 (o - y) \\cdot o (1 - o) \\cdot w_2^{[2]} \\cdot h_2 (1 - h_2) \\cdot x_1\n",
    "\\end{align*}\n",
    "\n",
    "where $h_2 = w_{1,2}^{[1]} x_1 + w_{2,2}^{[1]} x_2 + w_{0,2}^{[1]}$.\n",
    "\n",
    "Therefore, the gradient descent update rule for $w_{1,2}^{[1]}$ is\n",
    "\n",
    "$$w_{1,2}^{[1]} := w_{1,2}^{[1]} - \\alpha \\frac{2}{m} \\sum_{i = 1}^{m} (o^{(i)} - y^{(i)}) \\cdot o^{(i)} (1 - o^{(i)}) \\cdot w_2^{[2]} \\cdot h_2^{(i)} (1 - h_2^{(i)}) \\cdot x_1^{(i)}$$\n",
    "\n",
    "where $h_2^{(i)} = w_{1,2}^{[1]} x_1^{(i)} + w_{2,2}^{[1]} x_2^{(i)} + w_{0,2}^{[1]}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### (b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "It is possible. The three neurons can be treated as three independent linear classifiers. The three decision boundaries\n",
    "form a triangle that classifies the outside data into class 1, and the inside ones into class 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "\\begin{align*}\n",
    "w_{1,1}^{[1]} x_1 + x_{2,1}^{[1]} x_2 + w_{0,1}^{[1]} & = 0 \\\\\n",
    "w_{1,2}^{[1]} x_1 + x_{2,2}^{[1]} x_2 + w_{0,2}^{[1]} & = 0 \\\\\n",
    "w_{1,3}^{[1]} x_1 + x_{2,3}^{[1]} x_2 + w_{0,3}^{[1]} & = 0\n",
    "\\end{align*}\n",
    "\n",
    "Plug in some data points and solve the equations, we can obtain the weights. The weights vary upon the choice of the decision boundaries.\n",
    "Here is one possible solution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% code\n"
    }
   },
   "outputs": [],
   "source": [
    "w = {}\n",
    "\n",
    "w['hidden_layer_0_1'] = 0.5\n",
    "w['hidden_layer_1_1'] = -1\n",
    "w['hidden_layer_2_1'] = 0\n",
    "w['hidden_layer_0_2'] = 0.5\n",
    "w['hidden_layer_1_2'] = 0\n",
    "w['hidden_layer_2_2'] = -1\n",
    "w['hidden_layer_0_3'] = -4\n",
    "w['hidden_layer_1_3'] = 1\n",
    "w['hidden_layer_2_3'] = 1\n",
    "\n",
    "w['output_layer_0'] = -0.5\n",
    "w['output_layer_1'] = 1\n",
    "w['output_layer_2'] = 1\n",
    "w['output_layer_3'] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### (c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "No, it is not possible to achieve 100% accuracy using identity function as the activation functions for $h_1$, $h_2$ and $h_3$. Because\n",
    "\n",
    "\\begin{align*}\n",
    "o & = \\sigma (z^{[2]}) \\\\\n",
    "  & = \\sigma (W^{[2]} h + W_0^{[2]}) \\\\\n",
    "  & = \\sigma (W^{[2]} (W^{[1]} x + W_0^{[1]}) + W_0^{[2]}) \\\\\n",
    "  & = \\sigma (W^{[2]} W^{[1]} x + W^{[2]} W_0^{[1]} + W_0^{[2]}) \\\\\n",
    "  & = \\sigma (\\tilde{W} x + \\tilde{W_0})\n",
    "\\end{align*}\n",
    "\n",
    "where $\\tilde{W} = W^{[2]} W^{[1]}$ and $\\tilde{W_0} = W^{[2]} W_0^{[1]} + W_0^{[2]}$.\n",
    "\n",
    "We can see that the resulting classifier is still linear, and it is not able to classify datasets that are not linearly separable with 100% accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3055473888.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[1], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    You need to prove that finding the maximum likelihood estimate (MLE) for the parameter (\\theta) is equivalent to finding the distribution (P_\\theta) with minimal KL divergence from the empirical distribution (\\hat{P}).\u001b[0m\n\u001b[1;37m        ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You need to prove that finding the maximum likelihood estimate (MLE) for the parameter (\\theta) is equivalent to finding the distribution (P_\\theta) with minimal KL divergence from the empirical distribution (\\hat{P}).\n",
    "\n",
    "Definitions\n",
    "Empirical Distribution: $(\\hat{P}(x) = \\frac{1}{m} \\sum_{i=1}^m 1{x^{(i)} = x})$\n",
    "KL Divergence: $(D_{KL}(\\hat{P} \\parallel P_\\theta) = \\sum_x \\hat{P}(x) \\log \\frac{\\hat{P}(x)}{P_\\theta(x)})$\n",
    "Maximum Likelihood Estimate: $(\\theta_{MLE} = \\arg \\max_\\theta \\sum_{i=1}^m \\log P_\\theta(x^{(i)}))$\n",
    "Proof\n",
    "KL Divergence Expression: [ $D_{KL}(\\hat{P} \\parallel P_\\theta) = \\sum_x \\hat{P}(x) \\log \\frac{\\hat{P}(x)}{P_\\theta(x)}$ ]\n",
    "Substitute $(\\hat{P}(x)): Since (\\hat{P}(x) = \\frac{1}{m} \\sum_{i=1}^m 1{x^{(i)} = x})$, we can rewrite the KL divergence as: [ $D_{KL}(\\hat{P} \\parallel P_\\theta) = \\sum_x \\left( \\frac{1}{m} \\sum_{i=1}^m 1{x^{(i)} = x} \\right) \\log \\frac{\\frac{1}{m} \\sum_{i=1}^m 1{x^{(i)} = x}}{P_\\theta(x)}$ ]\n",
    "Simplify the Expression: [ $D_{KL}(\\hat{P} \\parallel P_\\theta) = \\frac{1}{m} \\sum_{i=1}^m \\log \\frac{\\hat{P}(x{(i)})}{P_\\theta(x{(i)})}$ ]\n",
    "Separate the Logarithm: [ $D_{KL}(\\hat{P} \\parallel P_\\theta) = \\frac{1}{m} \\sum_{i=1}^m \\left( \\log \\hat{P}(x^{(i)}) - \\log P_\\theta(x^{(i)}) \\right)$ ]\n",
    "Notice that $(\\hat{P}(x^{(i)}))$ is Constant: Since $(\\hat{P}(x^{(i)}))$ is the empirical probability, it is constant for all $(x^{(i)})$. Therefore, minimizing $(D_{KL}(\\hat{P} \\parallel P_\\theta))$ is equivalent to maximizing the second term: [ $\\arg \\min_\\theta D_{KL}(\\hat{P} \\parallel P_\\theta) = \\arg \\max_\\theta \\frac{1}{m} \\sum_{i=1}^m \\log P_\\theta(x^{(i)})$ ]\n",
    "Conclusion: [ $\\arg \\min_\\theta D_{KL}(\\hat{P} \\parallel P_\\theta) = \\arg \\max_\\theta \\sum_{i=1}^m \\log P_\\theta(x^{(i)})$ ]\n",
    "Thus, finding the maximum likelihood estimate for $(\\theta)$ is equivalent to finding the distribution $(P_\\theta)$ with minimal KL divergence from the empirical distribution $(\\hat{P})$.\n",
    "\n",
    "I hope this helps! Let me know if you have any questions or need further clarification.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$[ I(\\theta) = \\mathbb{E}{y \\sim p(y; \\theta)} \\left[ \\nabla{\\theta_0} \\log p(y; \\theta_0) \\nabla_{\\theta_0} \\log p(y; \\theta_0)^T \\bigg|{\\theta_0 = \\theta} \\right] - \\mathbb{E}{y \\sim p(y; \\theta)} \\left[ \\nabla_{\\theta_0} \\log p(y; \\theta_0) \\bigg|{\\theta_0 = \\theta} \\right] \\mathbb{E}{y \\sim p(y; \\theta)} \\left[ \\nabla_{\\theta_0} \\log p(y; \\theta_0) \\bigg|_{\\theta_0 = \\theta} \\right]^T ]$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
